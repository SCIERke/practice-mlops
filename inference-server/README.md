# Load Model
```python
  python YOUR_PROJECT_PATH/inference-server/utils/model_loader/load_model_cli.py --model-path TinyLlama/TinyLlama-1.1B-Chat-v1.0 --save-dir YOUR_SAVE_DIR
```